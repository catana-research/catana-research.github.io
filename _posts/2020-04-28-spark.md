---
layout: post
title: Spark
subtitle: Distributed computing
photo: fireworks-761547.jpg
photo-alt: Spark
tags: [Spark, Python]
category: [Systems]
---


PySpark

## DataFrames

https://www.analyticsvidhya.com/blog/2016/10/spark-dataframe-and-operations/#:~:text=1.,Excel%20sheet%20with%20Column%20headers.


## Hadoop

### Setup

### Setup on Ubuntu

Follow instructions on: https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/SingleCluster.html

Make sure to have Java installed:
```
sudo apt-get update
sudo apt install openjdk-8-jre
```
and that `JAVA_HOME` is set to the correct location in `hadoop-3.2.1\etc\hadoop\hadoop-env.sh`, this may be: `/usr/lib/jvm/java-8-openjdk-amd64`.

Also include the following are set, where username is your linux username:
```bash
export HDFS_NAMENODE_USER=username
export HDFS_DATANODE_USER=username
export HDFS_SECONDARYNAMENODE_USER=username
export YARN_RESOURCEMANAGER_USER=username
export YARN_NODEMANAGER_USER=username
```

Install PySpark with pip:
```bash
pip install pyspark
```


Start with: `hadoop-3.2.1\sbin\start-dfs.sh`.

### Access dashboard

localhost:9870


### Setup on Windows

Doesn't appear to work for version 3.2.1

https://towardsdatascience.com/installing-hadoop-3-2-1-single-node-cluster-on-windows-10-ac258dd48aef

Configuration for Hadoop cluster:

%HADOOP_HOME%\etc\hadoop\hdfs-site.xml
%HADOOP_HOME%\etc\hadoop\core-site.xml
%HADOOP_HOME%\etc\hadoop\mapred-site.xml
%HADOOP_HOME%\etc\hadoop\yarn-site.xml

### HDFS setup
Create the directories:
```cmd
V:\hadoop\data\dfs\datanode
V:\hadoop\data\dfs\namenode
```

Edit `hdfs-site.xml`, for a single cluster the replication value is `1`:

```cmd
<configuration>

<property>
<name>dfs.replication</name>
<value>1</value>
</property>
<property>
<name>dfs.namenode.name.dir</name>
<value>file:///V:/hadoop/data/dfs/namenode</value>
</property>
<property>
<name>dfs.datanode.data.dir</name>
<value>file:///V:/hadoop/data/dfs/datanode</value>
</property>

</configuration>
```
### Starting Hadoop

```cmd
cd %HADOOP_HOME%
.\sbin\start-dfs.cmd
```

If you have the error Missing `server' JVM (Java\jre8\bin\server\jvm.dll.), copy the contents of C:/Java/java/jre8/bin/client into a new folder C:/Java/java/jre8/bin/client. 


## Hive

## Impala

## Yarn

